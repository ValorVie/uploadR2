#!/usr/bin/env python3
"""
æ¸¬è©¦çŸ­æª”åç¢°æ’å’Œè‡ªå‹•å»¶å±•æ©Ÿåˆ¶

é©—è­‰ï¼š
1. çŸ­æª”åç”Ÿæˆå™¨åœ¨ç¢°æ’æ™‚çš„é‡è©¦æ©Ÿåˆ¶
2. é•·åº¦è‡ªå‹•å‡ç´šæ©Ÿåˆ¶
3. ä¿ç•™é—œéµå­—æª¢æŸ¥
4. ä¸¦ç™¼æƒ…æ³ä¸‹çš„çŸ­æª”åç”Ÿæˆ
"""

import asyncio
import tempfile
import threading
import time
import secrets
import string
from pathlib import Path
import sys
import os

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from src.config import Config
from src.database import DatabaseManager
from src.database.short_key_generator import ShortKeyGenerator
from src.database.exceptions import ShortKeyCollisionError, ShortKeyExhaustedError
from src.utils.database_integration import create_database_integration
from src.utils.logger import get_logger

logger = get_logger(__name__)


def create_test_config():
    """å‰µå»ºæ¸¬è©¦é…ç½®"""
    return Config(
        r2_endpoint_url="https://test.r2.cloudflarestorage.com",
        r2_access_key_id="test_access_key",
        r2_secret_access_key="test_secret_key",
        r2_bucket_name="test_bucket",
        enable_short_keys=True,
        check_duplicate=True,
        database_path="data/test_collision.db"  # ä½¿ç”¨å°ˆç”¨æ¸¬è©¦è³‡æ–™åº«
    )


def generate_dummy_file_record(short_key: str):
    """ç”Ÿæˆè™›æ“¬æª”æ¡ˆè¨˜éŒ„ç”¨æ–¼æ¸¬è©¦"""
    return {
        'uuid_key': f"test_uuid_{secrets.token_hex(16)}",
        'short_key': short_key,
        'original_filename': f"test_file_{short_key}.txt",
        'file_extension': '.txt',
        'file_size': 1024,
        'mime_type': 'text/plain',
        'sha512_hash': secrets.token_hex(64),
        'hash_algorithm': 'sha512',
        'r2_object_key': f"test/{short_key}.txt",
        'upload_url': f"https://test.com/{short_key}.txt",
        'upload_timestamp': '2024-01-01 00:00:00',
        'status': 'active'
    }


async def test_basic_short_key_generation():
    """æ¸¬è©¦åŸºæœ¬çŸ­æª”åç”Ÿæˆ"""
    logger.info("=== æ¸¬è©¦åŸºæœ¬çŸ­æª”åç”Ÿæˆ ===")
    
    config = create_test_config()
    db_manager = DatabaseManager(config.database_path, pool_size=5)
    
    try:
        generator = ShortKeyGenerator(db_manager)
        
        # ç”Ÿæˆä¸€äº›çŸ­æª”å
        generated_keys = []
        for i in range(10):
            short_key, length, salt = generator.generate_short_key()
            generated_keys.append(short_key)
            logger.info(f"ç”ŸæˆçŸ­æª”å {i+1}: {short_key} (é•·åº¦: {length})")
        
        # é©—è­‰æ²’æœ‰é‡è¤‡
        unique_keys = set(generated_keys)
        if len(unique_keys) == len(generated_keys):
            logger.info("âœ… çŸ­æª”åç”Ÿæˆç„¡é‡è¤‡")
        else:
            logger.error("âŒ ç™¼ç¾é‡è¤‡çš„çŸ­æª”å")
            return False
        
        # æª¢æŸ¥çµ±è¨ˆè³‡è¨Š
        stats = generator.get_statistics()
        logger.info(f"çµ±è¨ˆè³‡è¨Š: {stats}")
        
        return True
        
    except Exception as e:
        logger.error(f"åŸºæœ¬çŸ­æª”åç”Ÿæˆæ¸¬è©¦å¤±æ•—: {e}")
        return False
    
    finally:
        db_manager.close()


async def test_collision_handling():
    """æ¸¬è©¦ç¢°æ’è™•ç†æ©Ÿåˆ¶ - é€šéé å…ˆå¡«å……è³‡æ–™åº«ä¾†å‰µé€ ç¢°æ’æƒ…æ³"""
    logger.info("=== æ¸¬è©¦ç¢°æ’è™•ç†æ©Ÿåˆ¶ ===")
    
    config = create_test_config()
    db_manager = DatabaseManager(config.database_path, pool_size=5)
    
    try:
        generator = ShortKeyGenerator(db_manager)
        
        # æ­¥é©Ÿ1: æ’å…¥ä¿ç•™é—œéµå­—
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # æ’å…¥ä¸€äº›å¸¸è¦‹çš„ä¿ç•™é—œéµå­—
            reserved_keys = ["test", "api", "www", "admin", "root", "user", "file", "data"]
            for key in reserved_keys:
                cursor.execute("""
                    INSERT OR IGNORE INTO reserved_short_keys (short_key, reason)
                    VALUES (?, ?)
                """, (key, "æ¸¬è©¦ä¿ç•™é—œéµå­—"))
            
            conn.commit()
            logger.info(f"æ’å…¥äº† {len(reserved_keys)} å€‹ä¿ç•™é—œéµå­—")
        
        # æ­¥é©Ÿ2: é å…ˆå¡«å……ä¸€äº›4ä½çŸ­æª”ååˆ°è³‡æ–™åº«ï¼Œå‰µé€ ç¢°æ’ç’°å¢ƒ
        charset = string.digits + string.ascii_lowercase + string.ascii_uppercase
        pre_filled_keys = set()
        
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # ç”Ÿæˆä¸¦æ’å…¥50å€‹éš¨æ©Ÿ4ä½çŸ­æª”å
            logger.info("é å…ˆå¡«å……50å€‹4ä½çŸ­æª”åä¾†å¢åŠ ç¢°æ’æ©Ÿç‡...")
            for i in range(50):
                while True:
                    short_key = ''.join(secrets.choice(charset) for _ in range(4))
                    # ç¢ºä¿ä¸æ˜¯ä¿ç•™é—œéµå­—ä¸”æœªé‡è¤‡
                    if short_key not in reserved_keys and short_key not in pre_filled_keys:
                        pre_filled_keys.add(short_key)
                        break
                
                # æ’å…¥è™›æ“¬æª”æ¡ˆè¨˜éŒ„
                dummy_record = generate_dummy_file_record(short_key)
                cursor.execute("""
                    INSERT INTO file_records (
                        uuid_key, short_key, original_filename, file_extension,
                        file_size, mime_type, sha512_hash, hash_algorithm,
                        r2_object_key, upload_url, upload_timestamp, status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    dummy_record['uuid_key'], dummy_record['short_key'],
                    dummy_record['original_filename'], dummy_record['file_extension'],
                    dummy_record['file_size'], dummy_record['mime_type'],
                    dummy_record['sha512_hash'], dummy_record['hash_algorithm'],
                    dummy_record['r2_object_key'], dummy_record['upload_url'],
                    dummy_record['upload_timestamp'], dummy_record['status']
                ))
                
                if i % 10 == 0:
                    logger.info(f"å·²é å¡«å…… {i+1} å€‹çŸ­æª”å: {short_key}")
            
            conn.commit()
            logger.info(f"æˆåŠŸé å¡«å…… {len(pre_filled_keys)} å€‹4ä½çŸ­æª”å")
        
        # æ­¥é©Ÿ3: æ¸¬è©¦çŸ­æª”åç”Ÿæˆå™¨çš„ç¢°æ’è™•ç†èƒ½åŠ›
        logger.info("é–‹å§‹æ¸¬è©¦çŸ­æª”åç”Ÿæˆå™¨çš„ç¢°æ’è™•ç†...")
        
        generated_keys = set()
        generation_attempts = []
        reserved_collisions = 0
        existing_collisions = 0
        
        # å˜—è©¦ç”Ÿæˆ30å€‹æ–°çš„çŸ­æª”å
        for i in range(30):
            try:
                short_key, length, salt = generator.generate_short_key()
                
                # æª¢æŸ¥æ˜¯å¦èˆ‡é å¡«å……çš„æª”åè¡çª
                if short_key in pre_filled_keys:
                    existing_collisions += 1
                    logger.error(f"âŒ ç”Ÿæˆäº†å·²å­˜åœ¨çš„çŸ­æª”å: {short_key}")
                
                # æª¢æŸ¥æ˜¯å¦èˆ‡ä¿ç•™é—œéµå­—è¡çª
                if short_key in reserved_keys:
                    reserved_collisions += 1
                    logger.error(f"âŒ ç”Ÿæˆäº†ä¿ç•™é—œéµå­—: {short_key}")
                
                # æª¢æŸ¥å…§éƒ¨é‡è¤‡
                if short_key in generated_keys:
                    logger.error(f"âŒ ç”Ÿæˆäº†é‡è¤‡çŸ­æª”å: {short_key}")
                else:
                    generated_keys.add(short_key)
                
                generation_attempts.append({
                    'iteration': i + 1,
                    'short_key': short_key,
                    'length': length,
                    'is_new': short_key not in pre_filled_keys and short_key not in reserved_keys
                })
                
                if i % 5 == 0:
                    logger.info(f"ç¬¬ {i+1} å€‹çŸ­æª”å: {short_key} (é•·åº¦: {length}) {'âœ… æ–°' if generation_attempts[-1]['is_new'] else 'âŒ è¡çª'}")
                    
            except ShortKeyCollisionError as e:
                logger.error(f"çŸ­æª”åç¢°æ’éŒ¯èª¤ (ç¬¬ {i+1} æ¬¡å˜—è©¦): {e}")
                return False
            except Exception as e:
                logger.error(f"ç”ŸæˆçŸ­æª”åæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ (ç¬¬ {i+1} æ¬¡å˜—è©¦): {e}")
                return False
        
        # æ­¥é©Ÿ4: åˆ†æçµæœ
        successful_generations = len(generated_keys)
        new_unique_keys = len([a for a in generation_attempts if a['is_new']])
        
        logger.info(f"\n=== ç¢°æ’è™•ç†æ¸¬è©¦çµæœ ===")
        logger.info(f"ç¸½å˜—è©¦æ¬¡æ•¸: 30")
        logger.info(f"æˆåŠŸç”Ÿæˆå”¯ä¸€çŸ­æª”å: {successful_generations}")
        logger.info(f"ç”Ÿæˆçš„æ–°çŸ­æª”å (ç„¡è¡çª): {new_unique_keys}")
        logger.info(f"èˆ‡å·²å­˜åœ¨æª”åè¡çª: {existing_collisions}")
        logger.info(f"èˆ‡ä¿ç•™é—œéµå­—è¡çª: {reserved_collisions}")
        
        # æª¢æŸ¥é•·åº¦åˆ†å¸ƒ
        length_distribution = {}
        for attempt in generation_attempts:
            length = attempt['length']
            length_distribution[length] = length_distribution.get(length, 0) + 1
        
        logger.info(f"ç”Ÿæˆçš„çŸ­æª”åé•·åº¦åˆ†å¸ƒ: {length_distribution}")
        
        # æª¢æŸ¥æœ€çµ‚çµ±è¨ˆ
        stats = generator.get_statistics()
        logger.info("æœ€çµ‚çµ±è¨ˆè³‡è¨Š:")
        for seq in stats["sequences"]:
            logger.info(f"  é•·åº¦ {seq['length']}: {seq['current']}/{seq['max_possible']} ({seq['usage_percent']:.2f}%)")
        
        # åˆ¤æ–·æ¸¬è©¦æ˜¯å¦æˆåŠŸ
        # æˆåŠŸæ¢ä»¶ï¼š
        # 1. æ²’æœ‰èˆ‡å·²å­˜åœ¨æª”åçš„è¡çª
        # 2. æ²’æœ‰èˆ‡ä¿ç•™é—œéµå­—çš„è¡çª
        # 3. æ²’æœ‰å…§éƒ¨é‡è¤‡
        # 4. ç”Ÿæˆäº†é æœŸæ•¸é‡çš„å”¯ä¸€çŸ­æª”å
        
        test_passed = (
            existing_collisions == 0 and
            reserved_collisions == 0 and
            successful_generations == 30 and  # æ‡‰è©²ç”Ÿæˆ30å€‹å”¯ä¸€çŸ­æª”å
            new_unique_keys >= 25  # è‡³å°‘25å€‹æ‡‰è©²æ˜¯çœŸæ­£æ–°çš„
        )
        
        if test_passed:
            logger.info("âœ… ç¢°æ’è™•ç†æ©Ÿåˆ¶æ¸¬è©¦é€šé")
        else:
            logger.error("âŒ ç¢°æ’è™•ç†æ©Ÿåˆ¶æ¸¬è©¦å¤±æ•—")
            logger.error(f"å¤±æ•—åŸå› : å·²å­˜åœ¨è¡çª={existing_collisions}, ä¿ç•™å­—è¡çª={reserved_collisions}, å”¯ä¸€ç”Ÿæˆ={successful_generations}, æ–°æª”å={new_unique_keys}")
        
        return test_passed
        
    except Exception as e:
        logger.error(f"ç¢°æ’è™•ç†æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return False
    
    finally:
        db_manager.close()


async def test_length_escalation():
    """æ¸¬è©¦é•·åº¦å‡ç´šæ©Ÿåˆ¶ - é€šéå¯¦éš›å¡«æ»¿çŸ­æª”åç©ºé–“ä¾†è§¸ç™¼å‡ç´š"""
    logger.info("=== æ¸¬è©¦é•·åº¦å‡ç´šæ©Ÿåˆ¶ ===")
    
    config = create_test_config()
    db_manager = DatabaseManager(config.database_path, pool_size=5)
    
    try:
        generator = ShortKeyGenerator(db_manager)
        
        # æ­¥é©Ÿ1: é‡ç½®åºåˆ—è¡¨ï¼Œè¨­ç½®ä¸€å€‹éå¸¸å°çš„æœ€å¤§å€¼ä¾†å¿«é€Ÿè§¸ç™¼å‡ç´š
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # æ¸…ç©ºç¾æœ‰åºåˆ—ä¸¦é‡æ–°è¨­ç½®
            cursor.execute("DELETE FROM short_key_sequences")
            
            # è¨­ç½®é•·åº¦4çš„æœ€å¤§å€¼ç‚ºå¾ˆå°çš„æ•¸å­—ï¼ˆæ¯”å¦‚10ï¼‰ï¼Œé€™æ¨£å®¹æ˜“å¡«æ»¿
            small_max = 10
            cursor.execute("""
                INSERT INTO short_key_sequences (key_length, current_sequence, max_possible, exhausted)
                VALUES (4, 0, ?, FALSE)
            """, (small_max,))
            
            conn.commit()
            logger.info(f"è¨­ç½®é•·åº¦ 4 çš„æœ€å¤§å€¼ç‚º {small_max} ä»¥å¿«é€Ÿè§¸ç™¼å‡ç´š")
        
        # æ­¥é©Ÿ2: å…ˆç”¨è™›æ“¬è¨˜éŒ„å¡«æ»¿é•·åº¦4çš„ç©ºé–“
        charset = string.digits + string.ascii_lowercase + string.ascii_uppercase
        used_keys = set()
        
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # ç”Ÿæˆä¸€äº›4ä½çŸ­æª”åä¸¦æ’å…¥åˆ° file_records è¡¨ä¸­
            logger.info("é å…ˆå¡«å……4ä½çŸ­æª”ååˆ°è³‡æ–™åº«...")
            for i in range(small_max - 2):  # ç•™2å€‹ä½ç½®ï¼Œè®“ç”Ÿæˆå™¨å¯ä»¥å†ç”Ÿæˆå¹¾å€‹
                # ç”Ÿæˆ4ä½éš¨æ©ŸçŸ­æª”å
                while True:
                    short_key = ''.join(secrets.choice(charset) for _ in range(4))
                    if short_key not in used_keys:
                        used_keys.add(short_key)
                        break
                
                # å‰µå»ºè™›æ“¬æª”æ¡ˆè¨˜éŒ„
                dummy_record = generate_dummy_file_record(short_key)
                
                # æ’å…¥åˆ° file_records è¡¨
                cursor.execute("""
                    INSERT INTO file_records (
                        uuid_key, short_key, original_filename, file_extension,
                        file_size, mime_type, sha512_hash, hash_algorithm,
                        r2_object_key, upload_url, upload_timestamp, status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    dummy_record['uuid_key'], dummy_record['short_key'],
                    dummy_record['original_filename'], dummy_record['file_extension'],
                    dummy_record['file_size'], dummy_record['mime_type'],
                    dummy_record['sha512_hash'], dummy_record['hash_algorithm'],
                    dummy_record['r2_object_key'], dummy_record['upload_url'],
                    dummy_record['upload_timestamp'], dummy_record['status']
                ))
                
                if i % 5 == 0:
                    logger.info(f"å·²å¡«å…… {i+1} å€‹4ä½çŸ­æª”å: {short_key}")
            
            # æ›´æ–°åºåˆ—è¨ˆæ•¸
            cursor.execute("""
                UPDATE short_key_sequences
                SET current_sequence = ?
                WHERE key_length = 4
            """, (small_max - 2,))
            
            conn.commit()
            logger.info(f"å·²å¡«å…… {small_max - 2} å€‹4ä½çŸ­æª”ååˆ°è³‡æ–™åº«")
        
        # æ­¥é©Ÿ3: ç¾åœ¨å˜—è©¦ç”Ÿæˆæ–°çš„çŸ­æª”åï¼Œæ‡‰è©²æœƒè§¸ç™¼é•·åº¦å‡ç´š
        logger.info("é–‹å§‹ç”Ÿæˆæ–°çŸ­æª”åï¼Œé æœŸæœƒè§¸ç™¼é•·åº¦å‡ç´š...")
        print(f"\nğŸ“Š é–‹å§‹é•·åº¦å‡ç´šæ¸¬è©¦ - ç›®æ¨™: å¾4ä½å‡ç´šåˆ°5ä½")
        
        generated_keys = []
        length_changes = []
        
        for i in range(8):  # ç”Ÿæˆ8å€‹çŸ­æª”å
            try:
                print(f"\nğŸ”„ å˜—è©¦ç”Ÿæˆç¬¬ {i+1} å€‹çŸ­æª”å...")
                
                # åœ¨ç”Ÿæˆå‰æª¢æŸ¥ç•¶å‰åºåˆ—ç‹€æ…‹
                with db_manager.get_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT key_length, current_sequence, max_possible,
                               ROUND(CAST(current_sequence AS FLOAT) / max_possible * 100, 1) as usage_percent
                        FROM short_key_sequences
                        ORDER BY key_length
                    """)
                    
                    sequences_before = cursor.fetchall()
                    print(f"ğŸ“ˆ ç”Ÿæˆå‰åºåˆ—ç‹€æ…‹:")
                    for seq in sequences_before:
                        print(f"   é•·åº¦ {seq[0]}: {seq[1]}/{seq[2]} ({seq[3]}%)")
                
                short_key, length, salt = generator.generate_short_key()
                generated_keys.append(short_key)
                length_changes.append(length)
                
                print(f"âœ… ç¬¬ {i+1} å€‹ç”ŸæˆæˆåŠŸ: {short_key} (é•·åº¦: {length})")
                logger.info(f"ç¬¬ {i+1} å€‹ç”Ÿæˆçš„çŸ­æª”å: {short_key} (é•·åº¦: {length})")
                
                # å¦‚æœç”ŸæˆæˆåŠŸï¼Œä¹ŸæŠŠå®ƒåŠ å…¥åˆ°è³‡æ–™åº«ä¸­ï¼ˆæ¨¡æ“¬çœŸå¯¦ä½¿ç”¨æƒ…æ³ï¼‰
                with db_manager.get_connection() as conn:
                    cursor = conn.cursor()
                    dummy_record = generate_dummy_file_record(short_key)
                    cursor.execute("""
                        INSERT INTO file_records (
                            uuid_key, short_key, original_filename, file_extension,
                            file_size, mime_type, sha512_hash, hash_algorithm,
                            r2_object_key, upload_url, upload_timestamp, status
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        dummy_record['uuid_key'], dummy_record['short_key'],
                        dummy_record['original_filename'], dummy_record['file_extension'],
                        dummy_record['file_size'], dummy_record['mime_type'],
                        dummy_record['sha512_hash'], dummy_record['hash_algorithm'],
                        dummy_record['r2_object_key'], dummy_record['upload_url'],
                        dummy_record['upload_timestamp'], dummy_record['status']
                    ))
                    conn.commit()
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆç¬¬ {i+1} å€‹çŸ­æª”åæ™‚å‡ºéŒ¯: {e}")
                break
        
        # æ­¥é©Ÿ4: åˆ†æçµæœ
        unique_lengths = set(length_changes)
        logger.info(f"ç”Ÿæˆçš„çŸ­æª”åé•·åº¦åˆ†å¸ƒ: {dict((l, length_changes.count(l)) for l in unique_lengths)}")
        
        # æª¢æŸ¥çµ±è¨ˆè³‡è¨Š
        stats = generator.get_statistics()
        logger.info("æœ€çµ‚çµ±è¨ˆè³‡è¨Š:")
        for seq in stats["sequences"]:
            logger.info(f"  é•·åº¦ {seq['length']}: {seq['current']}/{seq['max_possible']} ({seq['usage_percent']:.2f}%) {'å·²ç”¨å®Œ' if seq['exhausted'] else 'å¯ç”¨'}")
        
        # é©—è­‰çµæœ - ä¿®æ­£åˆ¤æ–·é‚è¼¯
        # æª¢æŸ¥æ˜¯å¦æœ‰5ä½æˆ–æ›´é•·çš„çŸ­æª”åï¼ˆè­‰æ˜ç™¼ç”Ÿäº†å‡ç´šï¼‰
        max_length = max(unique_lengths) if unique_lengths else 4
        if max_length > 4:
            logger.info(f"âœ… æˆåŠŸæª¢æ¸¬åˆ°é•·åº¦å‡ç´š: å‡ç´šåˆ°{max_length}ä½")
            print(f"ğŸ‰ é•·åº¦å‡ç´šæˆåŠŸï¼å·²å‡ç´šåˆ° {max_length} ä½çŸ­æª”å")
            
            # æª¢æŸ¥4ä½åºåˆ—æ˜¯å¦è¢«æ¨™è¨˜ç‚ºå·²è€—ç›¡
            with db_manager.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT exhausted FROM short_key_sequences WHERE key_length = 4
                """)
                row = cursor.fetchone()
                if row and row[0]:
                    logger.info("âœ… 4ä½åºåˆ—å·²æ­£ç¢ºæ¨™è¨˜ç‚ºå·²è€—ç›¡")
                    print("âœ… 4ä½åºåˆ—å·²æ­£ç¢ºæ¨™è¨˜ç‚ºå·²è€—ç›¡")
                else:
                    logger.warning("âš ï¸  4ä½åºåˆ—æœªè¢«æ¨™è¨˜ç‚ºå·²è€—ç›¡")
                    print("âš ï¸  4ä½åºåˆ—æœªè¢«æ¨™è¨˜ç‚ºå·²è€—ç›¡")
            
            return True
        else:
            logger.warning(f"âŒ æœªæª¢æ¸¬åˆ°é•·åº¦å‡ç´šï¼Œæ‰€æœ‰é•·åº¦å‡ç‚º: {unique_lengths}")
            print(f"âŒ æœªæª¢æ¸¬åˆ°é•·åº¦å‡ç´šï¼Œæ‰€æœ‰é•·åº¦å‡ç‚º: {unique_lengths}")
            return False
            
    except Exception as e:
        logger.error(f"é•·åº¦å‡ç´šæ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return False
    
    finally:
        db_manager.close()


async def test_concurrent_generation():
    """æ¸¬è©¦ä¸¦ç™¼çŸ­æª”åç”Ÿæˆ"""
    logger.info("=== æ¸¬è©¦ä¸¦ç™¼çŸ­æª”åç”Ÿæˆ ===")
    
    config = create_test_config()
    db_manager = DatabaseManager(config.database_path, pool_size=10)
    
    try:
        generator = ShortKeyGenerator(db_manager)
        
        # ä¸¦ç™¼ç”ŸæˆçŸ­æª”å
        results = []
        errors = []
        
        def generate_keys_worker(worker_id, count):
            """å·¥ä½œç·šç¨‹å‡½æ•¸"""
            try:
                worker_keys = []
                for i in range(count):
                    short_key, length, salt = generator.generate_short_key()
                    worker_keys.append(short_key)
                    time.sleep(0.001)  # å°å»¶é²æ¨¡æ“¬çœŸå¯¦æƒ…æ³
                
                results.append((worker_id, worker_keys))
                logger.info(f"å·¥ä½œç·šç¨‹ {worker_id} å®Œæˆï¼Œç”Ÿæˆäº† {len(worker_keys)} å€‹çŸ­æª”å")
                
            except Exception as e:
                errors.append((worker_id, str(e)))
                logger.error(f"å·¥ä½œç·šç¨‹ {worker_id} å¤±æ•—: {e}")
        
        # å•Ÿå‹•å¤šå€‹å·¥ä½œç·šç¨‹
        threads = []
        worker_count = 5
        keys_per_worker = 10
        
        logger.info(f"å•Ÿå‹• {worker_count} å€‹ä¸¦ç™¼å·¥ä½œç·šç¨‹ï¼Œæ¯å€‹ç”Ÿæˆ {keys_per_worker} å€‹çŸ­æª”å")
        
        for worker_id in range(worker_count):
            thread = threading.Thread(
                target=generate_keys_worker,
                args=(worker_id, keys_per_worker)
            )
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰ç·šç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # æª¢æŸ¥çµæœ
        if errors:
            logger.error(f"âŒ æœ‰ {len(errors)} å€‹å·¥ä½œç·šç¨‹å¤±æ•—")
            for worker_id, error in errors:
                logger.error(f"  å·¥ä½œç·šç¨‹ {worker_id}: {error}")
            return False
        
        # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„çŸ­æª”å
        all_keys = []
        for worker_id, keys in results:
            all_keys.extend(keys)
        
        # æª¢æŸ¥é‡è¤‡
        unique_keys = set(all_keys)
        if len(unique_keys) == len(all_keys):
            logger.info(f"âœ… ä¸¦ç™¼ç”Ÿæˆ {len(all_keys)} å€‹çŸ­æª”åï¼Œç„¡é‡è¤‡")
            return True
        else:
            duplicates = len(all_keys) - len(unique_keys)
            logger.error(f"âŒ ä¸¦ç™¼ç”Ÿæˆç™¼ç¾ {duplicates} å€‹é‡è¤‡çŸ­æª”å")
            return False
            
    except Exception as e:
        logger.error(f"ä¸¦ç™¼ç”Ÿæˆæ¸¬è©¦å¤±æ•—: {e}")
        return False
    
    finally:
        db_manager.close()


async def test_forced_collision_scenario():
    """æ¸¬è©¦å¼·åˆ¶ç¢°æ’å ´æ™¯ - æ¨¡æ“¬æ¥µç«¯ç¢°æ’æƒ…æ³"""
    logger.info("=== æ¸¬è©¦å¼·åˆ¶ç¢°æ’å ´æ™¯ ===")
    
    config = create_test_config()
    db_manager = DatabaseManager(config.database_path, pool_size=5)
    
    try:
        generator = ShortKeyGenerator(db_manager)
        
        # æ­¥é©Ÿ1: å‰µå»ºä¸€å€‹æ¸¬è©¦ç©ºé–“ï¼ˆè¨­ç½®åˆç†å¤§å°ä½†èƒ½å¿«é€Ÿå¡«æ»¿ï¼‰
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # æ¸…ç©ºä¸¦é‡æ–°è¨­ç½®åºåˆ—ï¼Œå‰µå»ºä¸€å€‹æœ‰100å€‹ä½ç½®çš„æ¸¬è©¦ç©ºé–“
            cursor.execute("DELETE FROM short_key_sequences")
            test_max = 100  # è¼ƒå¤§çš„ç©ºé–“ï¼Œä½†ä»ç„¶å¯æ§
            cursor.execute("""
                INSERT INTO short_key_sequences (key_length, current_sequence, max_possible, exhausted)
                VALUES (4, 0, ?, FALSE)
            """, (test_max,))
            
            # æ¸…ç©ºä¿ç•™é—œéµå­—è¡¨ï¼Œç„¶å¾Œæ·»åŠ ä¸€äº›æœƒä½”ç”¨ç©ºé–“çš„ä¿ç•™å­—
            cursor.execute("DELETE FROM reserved_short_keys")
            
            # æ·»åŠ ä¸€äº›ç‰¹å®šçš„4ä½ä¿ç•™é—œéµå­—
            reserved_4char = ["test", "api", "www", "admin"]
            for key in reserved_4char:
                cursor.execute("""
                    INSERT INTO reserved_short_keys (short_key, reason)
                    VALUES (?, ?)
                """, (key, "å¼·åˆ¶ç¢°æ’æ¸¬è©¦"))
            
            conn.commit()
            print(f"ğŸ”§ è¨­ç½®æ¸¬è©¦ç©ºé–“: æœ€å¤§ {test_max} å€‹çµ„åˆ, ä¿ç•™ {len(reserved_4char)} å€‹é—œéµå­—")
            logger.info(f"è¨­ç½®æ¸¬è©¦ç©ºé–“: æœ€å¤§ {test_max} å€‹çµ„åˆ, ä¿ç•™ {len(reserved_4char)} å€‹é—œéµå­—")
        
        # æ­¥é©Ÿ2: é å…ˆå¡«æ»¿å¤§éƒ¨åˆ†å¯ç”¨ç©ºé–“ï¼ˆå¡«åˆ°85%ä»¥ä¸Šè§¸ç™¼å‡ç´šï¼‰
        charset = string.digits + string.ascii_lowercase + string.ascii_uppercase
        used_keys = set(reserved_4char)  # ä¿ç•™é—œéµå­—å·²ç¶“ä½”ç”¨
        
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # å¡«æ»¿åˆ°85å€‹ï¼ˆ85%ä½¿ç”¨ç‡ï¼‰ï¼Œé€™æ¨£æ‡‰è©²æœƒè§¸ç™¼å‡ç´š
            fill_count = 85
            print(f"ğŸ“¦ é å…ˆå¡«å…… {fill_count} å€‹4ä½çŸ­æª”åï¼ˆé”åˆ°85%ä½¿ç”¨ç‡ï¼‰...")
            logger.info(f"é å…ˆå¡«æ»¿ {fill_count} å€‹ä½ç½®...")
            
            for i in range(fill_count):
                while True:
                    short_key = ''.join(secrets.choice(charset) for _ in range(4))
                    if short_key not in used_keys:
                        used_keys.add(short_key)
                        break
                
                dummy_record = generate_dummy_file_record(short_key)
                cursor.execute("""
                    INSERT INTO file_records (
                        uuid_key, short_key, original_filename, file_extension,
                        file_size, mime_type, sha512_hash, hash_algorithm,
                        r2_object_key, upload_url, upload_timestamp, status
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    dummy_record['uuid_key'], dummy_record['short_key'],
                    dummy_record['original_filename'], dummy_record['file_extension'],
                    dummy_record['file_size'], dummy_record['mime_type'],
                    dummy_record['sha512_hash'], dummy_record['hash_algorithm'],
                    dummy_record['r2_object_key'], dummy_record['upload_url'],
                    dummy_record['upload_timestamp'], dummy_record['status']
                ))
                
                if i % 20 == 0 or i < 5:
                    print(f"   å¡«å……ç¬¬ {i+1} å€‹: {short_key}")
                    logger.info(f"å¡«å……ä½ç½® {i+1}: {short_key}")
            
            # æ›´æ–°åºåˆ—è¨ˆæ•¸
            cursor.execute("""
                UPDATE short_key_sequences
                SET current_sequence = ?
                WHERE key_length = 4
            """, (fill_count,))
            
            conn.commit()
            usage_percent = (fill_count / test_max) * 100
            print(f"âœ… å·²å¡«å…… {fill_count} å€‹ä½ç½®ï¼Œä½¿ç”¨ç‡: {usage_percent:.1f}%")
            logger.info(f"å·²ä½”ç”¨ {fill_count} å€‹ä½ç½®ï¼Œä½¿ç”¨ç‡: {usage_percent:.1f}%")
        
        # æ­¥é©Ÿ3: ç¾åœ¨å˜—è©¦ç”Ÿæˆæ›´å¤šçŸ­æª”åï¼Œæ¸¬è©¦é•·åº¦å‡ç´š
        logger.info("é–‹å§‹æ¸¬è©¦é•·åº¦å‡ç´šæ©Ÿåˆ¶...")
        
        generated_results = []
        
        # å˜—è©¦ç”Ÿæˆ5å€‹çŸ­æª”åï¼ˆè¶…éå‰©é¤˜ç©ºé–“ï¼‰
        for i in range(5):
            try:
                short_key, length, salt = generator.generate_short_key()
                generated_results.append({
                    'iteration': i + 1,
                    'short_key': short_key,
                    'length': length,
                    'salt': salt
                })
                
                logger.info(f"ç¬¬ {i+1} æ¬¡ç”Ÿæˆ: {short_key} (é•·åº¦: {length})")
                
                # å°‡ç”Ÿæˆçš„çŸ­æª”åä¹ŸåŠ å…¥è³‡æ–™åº«ï¼ˆæ¨¡æ“¬çœŸå¯¦ä½¿ç”¨ï¼‰
                if length == 4:  # å¦‚æœé‚„æ˜¯4ä½ï¼Œæª¢æŸ¥æ˜¯å¦æ‡‰è©²å‡ç´šäº†
                    if short_key in used_keys:
                        logger.error(f"âŒ ç”Ÿæˆäº†å·²å­˜åœ¨çš„çŸ­æª”å: {short_key}")
                        break
                    used_keys.add(short_key)
                
                # æ’å…¥ç”Ÿæˆçš„è¨˜éŒ„
                with db_manager.get_connection() as conn:
                    cursor = conn.cursor()
                    dummy_record = generate_dummy_file_record(short_key)
                    cursor.execute("""
                        INSERT INTO file_records (
                            uuid_key, short_key, original_filename, file_extension,
                            file_size, mime_type, sha512_hash, hash_algorithm,
                            r2_object_key, upload_url, upload_timestamp, status
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        dummy_record['uuid_key'], dummy_record['short_key'],
                        dummy_record['original_filename'], dummy_record['file_extension'],
                        dummy_record['file_size'], dummy_record['mime_type'],
                        dummy_record['sha512_hash'], dummy_record['hash_algorithm'],
                        dummy_record['r2_object_key'], dummy_record['upload_url'],
                        dummy_record['upload_timestamp'], dummy_record['status']
                    ))
                    conn.commit()
                
            except Exception as e:
                logger.error(f"ç¬¬ {i+1} æ¬¡ç”Ÿæˆå¤±æ•—: {e}")
                import traceback
                logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
                break
        
        # æ­¥é©Ÿ4: åˆ†æçµæœ
        if not generated_results:
            logger.error("âŒ ç„¡æ³•ç”Ÿæˆä»»ä½•çŸ­æª”å")
            return False
        
        lengths_generated = [r['length'] for r in generated_results]
        unique_lengths = set(lengths_generated)
        
        logger.info(f"\n=== å¼·åˆ¶ç¢°æ’æ¸¬è©¦çµæœ ===")
        logger.info(f"æˆåŠŸç”Ÿæˆ {len(generated_results)} å€‹çŸ­æª”å")
        logger.info(f"é•·åº¦åˆ†å¸ƒ: {dict((l, lengths_generated.count(l)) for l in unique_lengths)}")
        
        # æª¢æŸ¥çµ±è¨ˆè³‡è¨Š
        stats = generator.get_statistics()
        logger.info("æœ€çµ‚çµ±è¨ˆè³‡è¨Š:")
        for seq in stats["sequences"]:
            logger.info(f"  é•·åº¦ {seq['length']}: {seq['current']}/{seq['max_possible']} ({seq['usage_percent']:.2f}%) {'å·²ç”¨å®Œ' if seq['exhausted'] else 'å¯ç”¨'}")
        
        # é©—è­‰æ˜¯å¦ç™¼ç”Ÿäº†é•·åº¦å‡ç´š
        has_length_upgrade = len(unique_lengths) > 1 and max(unique_lengths) > 4
        
        if has_length_upgrade:
            logger.info("âœ… æˆåŠŸè§¸ç™¼é•·åº¦å‡ç´šæ©Ÿåˆ¶")
            return True
        else:
            logger.warning("âŒ æœªèƒ½è§¸ç™¼é•·åº¦å‡ç´šæ©Ÿåˆ¶")
            return False
        
    except Exception as e:
        logger.error(f"å¼·åˆ¶ç¢°æ’æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return False
    
    finally:
        db_manager.close()


async def test_integration_with_database():
    """æ¸¬è©¦èˆ‡è³‡æ–™åº«æ•´åˆçš„çŸ­æª”åè™•ç†"""
    logger.info("=== æ¸¬è©¦èˆ‡è³‡æ–™åº«æ•´åˆçš„çŸ­æª”åè™•ç† ===")
    
    config = create_test_config()
    db_integration = create_database_integration(config)
    
    if not db_integration:
        logger.error("ç„¡æ³•å‰µå»ºè³‡æ–™åº«æ•´åˆ")
        return False
    
    try:
        # å‰µå»ºæ¸¬è©¦æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("æ¸¬è©¦çŸ­æª”åç¢°æ’è™•ç†çš„æª”æ¡ˆå…§å®¹")
            test_file = Path(f.name)
        
        # æ¸¬è©¦å¤šæ¬¡å‰µå»ºç›¸åŒæª”æ¡ˆè¨˜éŒ„ï¼ˆæ‡‰è©²è§¸ç™¼é‡è¤‡æª¢æ¸¬ï¼‰
        logger.info("æ¸¬è©¦é‡è¤‡æª”æ¡ˆæª¢æ¸¬...")
        
        first_record = db_integration.create_file_record_from_path(
            test_file, "", ""
        )
        
        # ç¬¬ä¸€æ¬¡å­˜å„²
        file_id1 = db_integration.store_file_record(first_record)
        logger.info(f"ç¬¬ä¸€æ¬¡å­˜å„²æˆåŠŸï¼ŒçŸ­æª”å: {first_record.short_key}")
        
        # ç¬¬äºŒæ¬¡æ‡‰è©²æª¢æ¸¬åˆ°é‡è¤‡
        duplicate_check = db_integration.check_duplicate_file(test_file)
        if duplicate_check:
            logger.info(f"âœ… é‡è¤‡æª¢æ¸¬æˆåŠŸ: {duplicate_check.short_key}")
        else:
            logger.error("âŒ é‡è¤‡æª¢æ¸¬å¤±æ•—")
            return False
        
        # å˜—è©¦å†æ¬¡å­˜å„²ç›¸åŒæª”æ¡ˆï¼ˆæ‡‰è©²æ‹‹å‡º DuplicateFileErrorï¼‰
        try:
            second_record = db_integration.create_file_record_from_path(
                test_file, "", ""
            )
            file_id2 = db_integration.store_file_record(second_record)
            logger.error("âŒ æ‡‰è©²æª¢æ¸¬åˆ°é‡è¤‡æª”æ¡ˆä½†æ²’æœ‰")
            return False
            
        except Exception as e:
            logger.info(f"âœ… æ­£ç¢ºæª¢æ¸¬åˆ°é‡è¤‡æª”æ¡ˆ: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"è³‡æ–™åº«æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        return False
    
    finally:
        # æ¸…ç†
        if 'test_file' in locals() and test_file.exists():
            test_file.unlink()
        
        if db_integration:
            db_integration.close()


async def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=== çŸ­æª”åç¢°æ’å’Œè‡ªå‹•å»¶å±•æ©Ÿåˆ¶æ¸¬è©¦é–‹å§‹ ===")
    
    # æ¸…ç†æ¸¬è©¦è³‡æ–™åº«
    test_db_path = Path("data/test_collision.db")
    if test_db_path.exists():
        test_db_path.unlink()
        logger.info("æ¸…ç†èˆŠçš„æ¸¬è©¦è³‡æ–™åº«")
    
    try:
        # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
        tests = [
            ("åŸºæœ¬çŸ­æª”åç”Ÿæˆ", test_basic_short_key_generation()),
            ("ç¢°æ’è™•ç†æ©Ÿåˆ¶", test_collision_handling()),
            ("å¼·åˆ¶ç¢°æ’å ´æ™¯", test_forced_collision_scenario()),
            ("é•·åº¦å‡ç´šæ©Ÿåˆ¶", test_length_escalation()),
            ("ä¸¦ç™¼ç”Ÿæˆæ¸¬è©¦", test_concurrent_generation()),
            ("è³‡æ–™åº«æ•´åˆæ¸¬è©¦", test_integration_with_database()),
        ]
        
        results = []
        for test_name, test_coro in tests:
            logger.info(f"\n--- é–‹å§‹ {test_name} ---")
            try:
                result = await test_coro
                results.append((test_name, result))
                status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
                logger.info(f"{test_name}: {status}")
            except Exception as e:
                logger.error(f"{test_name} åŸ·è¡Œå¤±æ•—: {e}")
                results.append((test_name, False))
        
        # ç¸½çµ
        logger.info("\n=== æ¸¬è©¦ç¸½çµ ===")
        passed = sum(1 for _, result in results if result)
        total = len(results)
        
        for test_name, result in results:
            status = "âœ…" if result else "âŒ"
            logger.info(f"{status} {test_name}")
        
        logger.info(f"\nç¸½è¨ˆ: {passed}/{total} å€‹æ¸¬è©¦é€šé")
        
        if passed == total:
            print("\nğŸ‰ æ‰€æœ‰çŸ­æª”åç¢°æ’å’Œè‡ªå‹•å»¶å±•æ©Ÿåˆ¶æ¸¬è©¦é€šéï¼")
            print("âœ… çŸ­æª”åç”Ÿæˆå™¨ç¢°æ’è™•ç†æ­£å¸¸")
            print("âœ… é•·åº¦è‡ªå‹•å‡ç´šæ©Ÿåˆ¶æ­£å¸¸")
            print("âœ… ä¿ç•™é—œéµå­—æª¢æŸ¥æ­£å¸¸")
            print("âœ… ä¸¦ç™¼ç”Ÿæˆå®‰å…¨")
            print("âœ… è³‡æ–™åº«æ•´åˆé‡è¤‡æª¢æ¸¬æ­£å¸¸")
        else:
            print(f"\nâš ï¸  æœ‰ {total - passed} å€‹æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥èªŒ")
            
    except Exception as e:
        logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        print(f"\nâŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
    
    finally:
        # æ¸…ç†æ¸¬è©¦è³‡æ–™åº«
        if test_db_path.exists():
            test_db_path.unlink()
            logger.info("æ¸…ç†æ¸¬è©¦è³‡æ–™åº«")


if __name__ == "__main__":
    asyncio.run(main())