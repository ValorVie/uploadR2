# SQLite è³‡æ–™åº«ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

uploadR2 å°ˆæ¡ˆæ•´åˆäº†å®Œæ•´çš„ SQLite è³‡æ–™åº«ç³»çµ±ï¼Œæä¾›æª”æ¡ˆè¨˜éŒ„ç®¡ç†ã€é‡è¤‡æª”æ¡ˆæª¢æ¸¬ã€çŸ­æª”åç”Ÿæˆç­‰åŠŸèƒ½ã€‚æœ¬æ–‡ä»¶è©³è¿°å¦‚ä½•ä½¿ç”¨é€™äº›åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. åŸºæœ¬é…ç½®

åœ¨ `.env` æª”æ¡ˆä¸­é…ç½®è³‡æ–™åº«ç›¸é—œè¨­å®šï¼š

```bash
# è³‡æ–™åº«é…ç½®
DATABASE_PATH=data/uploadr2.db
DATABASE_POOL_SIZE=10

# çŸ­æª”åé…ç½®
ENABLE_SHORT_KEYS=true
SHORT_KEY_MIN_LENGTH=4
SHORT_KEY_CHARSET=alphanumeric_mixed
SHORT_KEY_SALT_LENGTH=16
MAX_SHORT_KEY_ATTEMPTS=100
```

### 2. é‹è¡Œæ¼”ç¤ºç¨‹å¼

```bash
# é‹è¡Œå®Œæ•´çš„è³‡æ–™åº«åŠŸèƒ½æ¼”ç¤º
uv run demo_database.py

# é‹è¡ŒåŸºæœ¬æ¸¬è©¦
uv run test_simple.py

# é‹è¡Œå®Œæ•´æ¸¬è©¦
uv run test_database.py
```

## ğŸ“š æ ¸å¿ƒåŠŸèƒ½

### è³‡æ–™åº«ç®¡ç†å™¨ (DatabaseManager)

```python
from src.database import DatabaseManager, FileRecord

# åˆå§‹åŒ–è³‡æ–™åº«ç®¡ç†å™¨
db_manager = DatabaseManager("data/uploadr2.db", pool_size=10)

# å­˜å„²æª”æ¡ˆè¨˜éŒ„
record = FileRecord(
    uuid_key="your-uuid-key",
    original_filename="example.jpg",
    file_extension=".jpg",
    file_size=1024000,
    mime_type="image/jpeg",
    sha512_hash="your-sha512-hash",
    r2_object_key="object-key.jpg",
    upload_url="https://your-domain.com/object-key.jpg"
)

file_id = db_manager.store_file_record(record)
print(f"æª”æ¡ˆè¨˜éŒ„å·²å­˜å„²ï¼ŒID: {file_id}, çŸ­æª”å: {record.short_key}")
```

### æª”æ¡ˆè¨˜éŒ„æŸ¥è©¢

```python
# é€šé UUID æŸ¥è©¢
record = db_manager.get_file_by_uuid("your-uuid-key")

# é€šéçŸ­æª”åæŸ¥è©¢  
record = db_manager.get_file_by_short_key("abc4")

# æª¢æŸ¥é‡è¤‡æª”æ¡ˆ
duplicate = db_manager.check_duplicate_by_hash("your-sha512-hash")
```

### çŸ­æª”åç”Ÿæˆ

```python
# ç”ŸæˆçŸ­æª”å
short_key, length, salt = db_manager._short_key_generator.generate_short_key()
print(f"ç”Ÿæˆçš„çŸ­æª”å: {short_key} (é•·åº¦: {length})")

# ç²å–çŸ­æª”åçµ±è¨ˆ
stats = db_manager._short_key_generator.get_statistics()
```

### è³‡æ–™åº«æ•´åˆå·¥å…·

```python
from src.utils.database_integration import create_database_integration
from src.config import load_config

# å‰µå»ºè³‡æ–™åº«æ•´åˆå¯¦ä¾‹
config = load_config()
db_integration = create_database_integration(config)

# æª¢æŸ¥é‡è¤‡æª”æ¡ˆ
duplicate_record = db_integration.check_duplicate_file(file_path)

# å‰µå»ºæª”æ¡ˆè¨˜éŒ„
file_record = db_integration.create_file_record_from_path(
    file_path, r2_object_key, upload_url
)

# å­˜å„²æª”æ¡ˆè¨˜éŒ„
file_id = db_integration.store_file_record(file_record)
```

## ğŸ—„ï¸ è³‡æ–™è¡¨çµæ§‹

### ä¸»è¦è³‡æ–™è¡¨

#### 1. file_recordsï¼ˆæª”æ¡ˆè¨˜éŒ„ä¸»è¡¨ï¼‰
- `id`: ä¸»éµï¼ˆè‡ªå‹•éå¢ï¼‰
- `uuid_key`: UUID é‡‘é‘°ï¼ˆå”¯ä¸€ï¼ŒåŸºæ–¼ SHA512ï¼‰
- `short_key`: çŸ­æª”åï¼ˆå”¯ä¸€ï¼Œ4-8 ç¢¼ï¼‰
- `original_filename`: åŸå§‹æª”å
- `file_extension`: å‰¯æª”å
- `file_size`: æª”æ¡ˆå¤§å°ï¼ˆä½å…ƒçµ„ï¼‰
- `mime_type`: MIME é¡å‹
- `sha512_hash`: SHA512 é›œæ¹Šå€¼
- `r2_object_key`: R2 å°è±¡é‡‘é‘°
- `upload_url`: å®Œæ•´è¨ªå• URL
- `upload_timestamp`: ä¸Šå‚³æ™‚é–“
- `status`: æª”æ¡ˆç‹€æ…‹ï¼ˆactive/deleted/archivedï¼‰
- `access_count`: è¨ªå•æ¬¡æ•¸
- `metadata`: JSON æ ¼å¼å…ƒæ•¸æ“š
- `tags`: JSON æ ¼å¼æ¨™ç±¤

#### 2. short_key_sequencesï¼ˆçŸ­æª”ååºåˆ—è¡¨ï¼‰
- `key_length`: çŸ­æª”åé•·åº¦
- `current_sequence`: ç•¶å‰åºè™Ÿ
- `max_possible`: æœ€å¤§å¯èƒ½æ•¸é‡
- `exhausted`: æ˜¯å¦å·²è€—ç›¡

#### 3. reserved_short_keysï¼ˆä¿ç•™çŸ­æª”åè¡¨ï¼‰
- `short_key`: ä¿ç•™çš„çŸ­æª”å
- `reason`: ä¿ç•™åŸå› 

#### 4. file_operation_logsï¼ˆæ“ä½œæ—¥èªŒè¡¨ï¼‰
- `file_record_id`: æª”æ¡ˆè¨˜éŒ„ ID
- `operation_type`: æ“ä½œé¡å‹ï¼ˆupload/access/delete/updateï¼‰
- `operation_details`: JSON æ ¼å¼æ“ä½œè©³æƒ…
- `timestamp`: æ“ä½œæ™‚é–“

## ğŸ”‘ çŸ­æª”åç³»çµ±

### ç‰¹æ€§
- **å®‰å…¨æ€§**: ä½¿ç”¨åŠ å¯†å®‰å…¨çš„éš¨æ©Ÿç”Ÿæˆ
- **é˜²çŒœæ¸¬**: çµåˆé¹½å€¼å’Œå¤šå±¤éš¨æ©ŸåŒ–
- **æ¼¸é€²å¼é•·åº¦**: å¾ 4 ä½é–‹å§‹ï¼Œéœ€è¦æ™‚è‡ªå‹•å‡ç´š
- **é«˜æ•ˆèƒ½**: æ¯ç§’å¯ç”Ÿæˆæ•¸åƒå€‹å”¯ä¸€çŸ­æª”å
- **ç¢°æ’è™•ç†**: è‡ªå‹•é‡è©¦å’Œé•·åº¦å‡ç´šæ©Ÿåˆ¶

### å­—ç¬¦é›†
- æ•¸å­—: 0-9 (10 å€‹)
- å°å¯«å­—æ¯: a-z (26 å€‹)  
- å¤§å¯«å­—æ¯: A-Z (26 å€‹)
- ç¸½è¨ˆ: 62 å€‹å­—ç¬¦

### å®¹é‡è¨ˆç®—
- 4 ä½: 62â´ â‰ˆ 1480è¬å€‹çµ„åˆ
- 5 ä½: 62âµ â‰ˆ 9.16å„„å€‹çµ„åˆ
- 6 ä½: 62â¶ â‰ˆ 568å„„å€‹çµ„åˆ

## ğŸ“Š çµ±è¨ˆèˆ‡ç›£æ§

### ç²å–çµ±è¨ˆè³‡è¨Š

```python
# ç²å–å®Œæ•´çµ±è¨ˆ
stats = db_manager.get_statistics()

print(f"ç¸½æª”æ¡ˆæ•¸: {stats['total_files']}")
print(f"ç¸½å¤§å°: {stats['total_size_mb']} MB")
print(f"çŸ­æª”åä½¿ç”¨æƒ…æ³:")

for seq in stats['short_key_statistics']['sequences']:
    print(f"  é•·åº¦ {seq['length']}: {seq['current']}/{seq['max_possible']} ({seq['usage_percent']}%)")
```

### æª”æ¡ˆé¡å‹åˆ†å¸ƒ

```python
for ext_info in stats['extension_distribution']:
    print(f"{ext_info['extension']}: {ext_info['count']} å€‹æª”æ¡ˆ")
```

## ğŸ”§ é€²éšä½¿ç”¨

### è‡ªå®šç¾©çŸ­æª”åç”Ÿæˆ

```python
from src.database.short_key_generator import ShortKeyGenerator

# è‡ªå®šç¾©ç”Ÿæˆå™¨
generator = ShortKeyGenerator(db_manager)

# æ‰¹é‡ç”Ÿæˆ
keys = []
for i in range(100):
    key, length, salt = generator.generate_short_key()
    keys.append(key)

print(f"ç”Ÿæˆäº† {len(set(keys))} å€‹å”¯ä¸€çŸ­æª”å")
```

### è³‡æ–™åº«é·ç§»

```python
# å‚™ä»½ç¾æœ‰è³‡æ–™åº«
import shutil
shutil.copy("data/uploadr2.db", "data/uploadr2.db.backup")

# æª¢æŸ¥è³‡æ–™åº«æ¶æ§‹ç‰ˆæœ¬
with db_manager.get_connection() as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT version FROM schema_version ORDER BY applied_at DESC LIMIT 1")
    version = cursor.fetchone()
    print(f"ç•¶å‰è³‡æ–™åº«ç‰ˆæœ¬: {version[0] if version else 'æœªçŸ¥'}")
```

### æ•ˆèƒ½å„ªåŒ–

```python
# èª¿æ•´è³‡æ–™åº«è¨­å®š
with db_manager.get_connection() as conn:
    conn.execute("PRAGMA cache_size = 20000")  # å¢åŠ å¿«å–
    conn.execute("PRAGMA temp_store = MEMORY")  # ä½¿ç”¨è¨˜æ†¶é«”æš«å­˜
    conn.execute("PRAGMA mmap_size = 268435456")  # 256MB memory-mapped I/O
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. è³‡æ–™åº«æª”æ¡ˆæœªæ‰¾åˆ°
```bash
# ç¢ºä¿ data ç›®éŒ„å­˜åœ¨
mkdir -p data

# æª¢æŸ¥æª”æ¡ˆæ¬Šé™
ls -la data/uploadr2.db
```

#### 2. çŸ­æª”åç”Ÿæˆå¤±æ•—
```python
# æª¢æŸ¥åºåˆ—ç‹€æ…‹
stats = db_manager._short_key_generator.get_statistics()
for seq in stats['sequences']:
    if seq['exhausted']:
        print(f"é•·åº¦ {seq['length']} å·²è€—ç›¡")
```

#### 3. è³‡æ–™åº«é–å®š
```python
# æª¢æŸ¥æ´»å‹•é€£æ¥
import sqlite3
try:
    conn = sqlite3.connect("data/uploadr2.db", timeout=1.0)
    conn.close()
    print("è³‡æ–™åº«å¯æ­£å¸¸è¨ªå•")
except sqlite3.OperationalError as e:
    print(f"è³‡æ–™åº«è¨ªå•éŒ¯èª¤: {e}")
```

### æ—¥èªŒæª¢æŸ¥

```python
from src.utils.logger import get_logger

# å•Ÿç”¨è©³ç´°æ—¥èªŒ
logger = get_logger("database")
logger.setLevel("DEBUG")

# æª¢æŸ¥è³‡æ–™åº«æ“ä½œæ—¥èªŒ
with db_manager.get_connection() as conn:
    cursor = conn.cursor()
    cursor.execute("""
        SELECT operation_type, COUNT(*) 
        FROM file_operation_logs 
        GROUP BY operation_type
    """)
    for row in cursor.fetchall():
        print(f"{row[0]}: {row[1]} æ¬¡æ“ä½œ")
```

## ğŸ“ æœ€ä½³å¯¦è¸

### 1. è³‡æ–™åº«ç¶­è­·
```python
# å®šæœŸåŸ·è¡Œ VACUUM æ¸…ç†è³‡æ–™åº«
with db_manager.get_connection() as conn:
    conn.execute("VACUUM")

# æ›´æ–°çµ±è¨ˆè³‡è¨Š
with db_manager.get_connection() as conn:
    conn.execute("ANALYZE")
```

### 2. å‚™ä»½ç­–ç•¥
```python
import datetime
import shutil

# è‡ªå‹•å‚™ä»½
backup_name = f"uploadr2_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
shutil.copy("data/uploadr2.db", f"backups/{backup_name}")
```

### 3. ç›£æ§æŒ‡æ¨™
- è³‡æ–™åº«æª”æ¡ˆå¤§å°
- çŸ­æª”åä½¿ç”¨ç‡
- æŸ¥è©¢å›æ‡‰æ™‚é–“
- éŒ¯èª¤ç‡çµ±è¨ˆ

## ğŸ”— ç›¸é—œæ–‡ä»¶

- [è³‡æ–™åº«æ¶æ§‹è¨­è¨ˆ](database_architecture_design.md)
- [API æ–‡ä»¶](../README.md)
- [é…ç½®æŒ‡å—](../src/config.py)

## ğŸ“ æŠ€è¡“æ”¯æ´

å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥ï¼š
1. è³‡æ–™åº«æª”æ¡ˆæ¬Šé™
2. æ—¥èªŒæª”æ¡ˆå…§å®¹
3. é…ç½®æª”æ¡ˆè¨­å®š
4. ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³

æ›´å¤šè©³ç´°è³‡è¨Šè«‹åƒè€ƒå®Œæ•´çš„æ¶æ§‹è¨­è¨ˆæ–‡ä»¶ã€‚